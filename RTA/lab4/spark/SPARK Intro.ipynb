{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc14d58f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Podsumowanie poprzednich zajęć \n",
    "\n",
    "Na poprzednich dwóch zajęciach laboratoryjnych zrealizowaliśmy zagadnienia dotyczące przetwarzania danych ustrukturyzowanych i nieustrukturyzowanych w trybie wsadowym. Ponadto przygotowaliśmy środowisko produkcyjne (z wykorzystaniem biblioteki FLASK) wykorzystujące model napisany w pełni obiektowo otrzymany po wstępnym przetworzeniu danych (irys).   \n",
    "\n",
    "1. Ustrukturyzowane dane - tablice numpy, ramki danych Pandas, tabele danych w bazach SQL (tworzenie, filtrowanie, modyfikacja)\n",
    "2. Nieustrukturyzowane dane - JSON, tensory numpy (odczyt, zapis, przetworzenie)\n",
    "3. Wykorzystanie obiektowego programowania w Pythonie - podstawa budowy klas, tworzenie obiektów, korzystanie z pól obiektów i metod (funkcji). \n",
    "4. Stworzenie modelu klasyfikacji binarnej opartego o sieć perceprtornu oraz wykorzystującą algorytm Adeline napisany obiektowo w pełnej analogii do modeli z biblioteki sklearn.\n",
    "5. Wykorzystanie środowiska SQLAlchemy do łączenia się z bazami danych. \n",
    "6. Strona www realizująca API z wykorzystaniem modelu - nowe dane w czasie rzeczywistym + prognoza - Jako system odpytywania modelu w czasie rzeczywistym (Zastanów się jak go unowocześnić) \n",
    "\n",
    "\n",
    "Podczas przerabiania dowolnych technik uczenia maszynowego najczęściej (jeśli nie zawsze) jesteśmy uczeni realizacji zadań takiego systemu z podziałem na trzy podstawowe kategorie:\n",
    "\n",
    "1. Uczenie nadzorowane  - supervised learning\n",
    "    - klasyfikacja - zrealizowany na poprzednich ćwiczeniach\n",
    "    - Regresja liniowa\n",
    "2. Uczenie nienadzorowane - unsupervised learning\n",
    "3. Uczenie przez wzmacnianie - reinforcement learning\n",
    "\n",
    "Jednak systemy te można również klasyfikować ze względu na `możliwość trenowania przyrostowego przy użyciu strumienia nadsyłanych danych`\n",
    "\n",
    "1. **Uczenie wsadowe - batch learning**. To system w którym do jego nauki musisz wykorzysać wszytkie zapisane i już istniejące dane. Zajmuje zazwyczaj dużo czasu i zasobów - przeprowadzany w trybie offline. System wpierw jest uczony, a następnie zostaje wdrożony do cyklu produkcyjnego i już więcej nie jest trenowany (korzysta tylko ze zdobytych wcześniej informacji). Zajwisko to nazywane jest **uczeniem offline**. \n",
    "\n",
    "Jeśli chcesz aby system uczenia wsadowego brał pod uwagę nowe dane to musisz od podstaw wytrenować nową wersję systemu przy użyciu wszystkich dostępnch danych, wyłączyć stary system i zastąpić go nowym. Na szczęście proces ten jest w pełni automatyzowalny. Jednak trzeba pamiętać, iż trenowanie nowego modelu na pełnym zbiorze danych może trwać bardzo długo (i jest dość kosztowne) stąd wymiana modeli pojawia się np raz na tydzień raz na dzień. W przypadku bardzo dużej ilości informacji system taki może szybko przestać działać - zamiast wykonywać swoje zadania będzie obliczał nowy model. \n",
    "\n",
    "2. W procesie **uczenia przyrostowego - online learning** system trenowany jest na bieżąco poprzez sekwencyjne dostarczanie danych (pojedyncze lub minipaczki - mini-batches). Każdy krok uczenia jest szybki i mało kosztowny. Uczenie następuje w momencie pojawienia się nowych danych.  \n",
    "\n",
    "Uczenie przyrostowe sprawdza się wszędzie tam gdzie układ odbiera ciągły strumień danych (urządzenia IoT, giełda) i wymagana jest szybkie i autonomiczne dopasowanie do nowych warunków. Przydaje się również przy pracy z ograniczonymi zasobami obliczeniowymi (stare dane nie są istotne).\n",
    "\n",
    "Dużym problemem uczenia przyrostowego jest stopniowy spadek wydajności systemu w przypadku gdy dostarczone dane przestają być prawidłowe. Np. uszkodzony czujnik, celowe zasypywanie przeglądarki danymi w celu podbicia rankingu w wynikach wyszukiwania (algorytmy wykrywania anomalii).\n",
    "\n",
    "\n",
    "[Stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)\n",
    "\n",
    "[Stochastic learning](https://leon.bottou.org/publications/pdf/mlss-2003.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2c19e5",
   "metadata": {},
   "source": [
    "## Środowisko Apache SPARK\n",
    "\n",
    "[książka](https://pages.databricks.com/rs/094-YMS-629/images/LearningSpark2.0.pdf) \n",
    "\n",
    "\n",
    "1. Silnik analityczny do przetwarzania danych na dużą skalę\n",
    "2. Projekt open source, od 2013 w Apache Software FOundation\n",
    "3. Napisany w Scali \n",
    "4. Udostępnia API w Java, Scala, Python, R \n",
    "\n",
    "\n",
    "### Instalacja i uruchomienie \n",
    "\n",
    "1. Wersja trywialna (Docker) \n",
    "\n",
    "```{bash}\n",
    "docker run -d -p 8888:8888 -v \"full_path_to_your_folder:/notebooks\" sebkaz/docker-spark-jupyter\n",
    "```\n",
    "\n",
    "```{bash}\n",
    "docker run -d -p 8888:8888 -v \"full_path_to_your_folder:/notebooks\" jupyter/pyspark-notebook\n",
    "```\n",
    "\n",
    "2. Wersja trywialna trywialna (komputer ze środowiskiem Python + JDK JAVA przynajmniej w wersji 8) \n",
    "\n",
    "    - [Ściągnij katalog](https://www.apache.org/dyn/closer.lua/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz)\n",
    "    - Rozpakuj np 7z\n",
    "    - umieść w wygodnym miejscu i zapisz ścieżkę (będzie potrzebna do findspark() )\n",
    "    - uruchom jupyter notebook'a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f53f8596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "#findspark.init(\"C:\\\\Users\\\\Vlad\\\\Documents\\\\SGH\\\\RTA\\\\spark\")\n",
    "#findspark.init(\"/Users/air/Desktop/spark/\") # on my mac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9ebc8a",
   "metadata": {},
   "source": [
    "### SparkContext\n",
    "\n",
    "1. Główny, podstawowy obiekt\n",
    "2. Punkt wejścia do pracy ze Sparkiem\n",
    "3. Generowanie obiektów RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf34403c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/09/15 07:28:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# inicjalizacja SparkContext\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext(appName=\"myAppName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc8f02f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://81ffefea6f22:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>myAppName</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=myAppName>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f1dcd1",
   "metadata": {},
   "source": [
    "### SparkSession\n",
    "\n",
    "1. Główny punkt wyjścia do SparkSQL\n",
    "2. Opakowuje (wrapper) SparkContext\n",
    "3. Zazwyczaj pierwszy obiekt, który będziemy tworzyć"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fabfff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"new\")\\\n",
    "        .getOrCreate()\n",
    "# otrzymanie obiektu SparkContext\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1771dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://81ffefea6f22:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>myAppName</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f1f244abcd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fbe2c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://81ffefea6f22:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>myAppName</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=myAppName>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9871dcc0",
   "metadata": {},
   "source": [
    "### RDD\n",
    "\n",
    "- Resilient Distributed Dataset\n",
    "- Podstawowa abstrakcja oraz rdzeń Sparka\n",
    "- Obsługiwane przez dwa rodzaje operacji:\n",
    "    - Akcje:\n",
    "        - operacje uruchamiające/ egzekucję transformacji na RDD\n",
    "        - przyjmują RDD jako input i zwracają wynik NIE będący RDD\n",
    "    - Transformacje:\n",
    "        - leniwe operacje\n",
    "        - przyjmują RDD i zwracają RDD\n",
    "\n",
    "- In-Memory - dane RDD przechowywane w pamięci\n",
    "- Immutable \n",
    "- Lazy evaluated\n",
    "- Parallel - przetwarzane równolegle\n",
    "- Partitioned - rozproszone \n",
    "\n",
    "## WAŻNE informacje !\n",
    "\n",
    "Ważne do zrozumienia działania SPARKA:\n",
    "\n",
    "Term                   |Definition\n",
    "----                   |-------\n",
    "RDD                    |Resilient Distributed Dataset\n",
    "Transformation         |Spark operation that produces an RDD\n",
    "Action                 |Spark operation that produces a local object\n",
    "Spark Job              |Sequence of transformations on data with a final action\n",
    "\n",
    "\n",
    "Dwie podstawowe metody tworzenia RDD:\n",
    "\n",
    "Method                      |Result\n",
    "----------                               |-------\n",
    "`sc.parallelize(array)`                  |Create RDD of elements of array (or list)\n",
    "`sc.textFile(path/to/file)`                      |Create RDD of lines from file\n",
    "\n",
    "Podstawowe transformacje\n",
    "\n",
    "Transformation Example                          |Result\n",
    "----------                               |-------\n",
    "`filter(lambda x: x % 2 == 0)`           |Discard non-even elements\n",
    "`map(lambda x: x * 2)`                   |Multiply each RDD element by `2`\n",
    "`map(lambda x: x.split())`               |Split each string into words\n",
    "`flatMap(lambda x: x.split())`           |Split each string into words and flatten sequence\n",
    "`sample(withReplacement=True,0.25)`      |Create sample of 25% of elements with replacement\n",
    "`union(rdd)`                             |Append `rdd` to existing RDD\n",
    "`distinct()`                             |Remove duplicates in RDD\n",
    "`sortBy(lambda x: x, ascending=False)`   |Sort elements in descending order\n",
    "\n",
    "Podstawowe akcje \n",
    "\n",
    "Action                             |Result\n",
    "----------                             |-------\n",
    "`collect()`                            |Convert RDD to in-memory list \n",
    "`take(3)`                              |First 3 elements of RDD \n",
    "`top(3)`                               |Top 3 elements of RDD\n",
    "`takeSample(withReplacement=True,3)`   |Create sample of 3 elements with replacement\n",
    "`sum()`                                |Find element sum (assumes numeric elements)\n",
    "`mean()`                               |Find element mean (assumes numeric elements)\n",
    "`stdev()`                              |Find element deviation (assumes numeric elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbd71a9",
   "metadata": {},
   "source": [
    "-----\n",
    "- **parallelize(c)** - tworzenie RDD na podstawie lokalnej kolekcji\n",
    "- **map(f)** - zwraca nowe RDD po zastosowaniu podanej funkcji na każdym elemencie oryginalnego RDD (**T**)\n",
    "- **filter(f)** - zwraca nowe RDD zawierające jedynie elementy które spełniają predykat (**T**)\n",
    "- **reduce(f)** - agreguje elementy zbioru wykorzystując podaną funkcję. Funkcja redukująca musi być asocjacyjna [(a x b) x c = a x (b x c)] i przemienna [a x b = b x a] (**A**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c17960d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(10)) # utworzenie RDD \n",
    "\n",
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94abdbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect() # akcja "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa737270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "496abf13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 2, 7]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.takeSample(True,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0384f48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 0, 4]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.takeSample(False,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e41a2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "161fa1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd07a615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting example.txt\n"
     ]
    }
   ],
   "source": [
    "%%file example.txt\n",
    "first \n",
    "second line\n",
    "the third line\n",
    "then a fourth line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc41d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rdd = sc.textFile('example.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae1e0674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "320c9cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first ', 'second line', 'the third line']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eca13c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['second line', 'the third line']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rdd.takeSample(True,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a42eeaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first ', 'second line']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rdd.takeSample(False,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28613628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beb193d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = sc.parallelize(range(1,20))\n",
    "rdd2 = sc.parallelize(range(10,25))\n",
    "rdd3 = rdd1.union(rdd2)\n",
    "rdd3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "313469f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 16,\n",
       " 24,\n",
       " 1,\n",
       " 9,\n",
       " 17,\n",
       " 2,\n",
       " 10,\n",
       " 18,\n",
       " 3,\n",
       " 11,\n",
       " 19,\n",
       " 4,\n",
       " 12,\n",
       " 20,\n",
       " 5,\n",
       " 13,\n",
       " 21,\n",
       " 6,\n",
       " 14,\n",
       " 22,\n",
       " 7,\n",
       " 15,\n",
       " 23]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4 = rdd3.distinct()\n",
    "rdd4.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9352104f",
   "metadata": {},
   "source": [
    "-----\n",
    "- **parallelize(c)** - tworzenie RDD na podstawie lokalnej kolekcji\n",
    "- **map(f)** - zwraca nowe RDD po zastosowaniu podanej funkcji na każdym elemencie oryginalnego RDD (**T**)\n",
    "- **filter(f)** - zwraca nowe RDD zawierające jedynie elementy które spełniają predykat (**T**)\n",
    "- **reduce(f)** - agreguje elementy zbioru wykorzystując podaną funkcję. Funkcja redukująca musi być asocjacyjna [(a x b) x c = a x (b x c)] i przemienna [a x b = b x a] (**A**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53ea661",
   "metadata": {},
   "source": [
    "#### Map vs. FlatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fed470be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['first'],\n",
       " ['second', 'line'],\n",
       " ['the', 'third', 'line'],\n",
       " ['then', 'a', 'fourth', 'line']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rdd.map(lambda line: line.split()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e70f0f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first',\n",
       " 'second',\n",
       " 'line',\n",
       " 'the',\n",
       " 'third',\n",
       " 'line',\n",
       " 'then',\n",
       " 'a',\n",
       " 'fourth',\n",
       " 'line']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect everything as a single flat map\n",
    "text_rdd.flatMap(lambda line: line.split()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c4eeb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(range(20)) \\\n",
    "    .map(lambda x: x * 2) \\\n",
    "    .filter(lambda x: x != 2) \\\n",
    "    .reduce(lambda x,y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e52b976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(range(20)).collect() # rozproszenie -> parallelize -> collect powrot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f2a7c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(range(20)).map(lambda x: x * 2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ef8db67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(range(20)) \\\n",
    "    .map(lambda x: x * 2).filter(lambda x: x != 2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2452af",
   "metadata": {},
   "source": [
    "----\n",
    "- **textFile(p)** - tworzenie RDD na podstawie pliku. Jeden wiersz = jeden element RDD\n",
    "- **flatMap(f)** - zwraca nowe RDD po zastosowaniu podanej funkcji na każdym elemencie oryginalnego RDD oraz spłaszczeniu rezultatu (**T**)\n",
    "- **reduceByKey(f)** - zwraca RDD z połączonymi wartościami dla każdego klucza. Funkcja redukująca musi być asocjacyjna [(a x b) x c = a x (b x c)] i przemienna [a x b = b x a] (**T**)\n",
    "- **collect()** - zwraca elementy RDD na driver (**A**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c64edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e2c06a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 12),\n",
       " ('engine', 1),\n",
       " ('compatible', 1),\n",
       " ('hadoop', 3),\n",
       " ('run', 1),\n",
       " ('in', 3),\n",
       " ('clusters', 1),\n",
       " ('yarn', 1),\n",
       " (\"spark's\", 1),\n",
       " ('mode', 1),\n",
       " ('process', 1),\n",
       " ('hdfs', 1),\n",
       " ('cassandra', 1),\n",
       " ('hive', 1),\n",
       " ('designed', 1),\n",
       " ('perform', 1),\n",
       " ('both', 1),\n",
       " ('similar', 1),\n",
       " ('new', 1),\n",
       " ('like', 1),\n",
       " ('streaming', 1),\n",
       " ('machine', 1),\n",
       " ('learning', 1),\n",
       " ('than', 8),\n",
       " ('implicit', 1),\n",
       " ('simple', 1),\n",
       " ('complicated', 1),\n",
       " ('flat', 1),\n",
       " ('nested', 1),\n",
       " ('sparse', 1),\n",
       " ('readability', 1),\n",
       " ('counts', 1),\n",
       " ('cases', 1),\n",
       " (\"aren't\", 1),\n",
       " ('rules', 1),\n",
       " ('although', 3),\n",
       " ('errors', 1),\n",
       " ('never', 3),\n",
       " ('pass', 1),\n",
       " ('explicitly', 1),\n",
       " ('silenced', 1),\n",
       " ('of', 2),\n",
       " ('refuse', 1),\n",
       " ('temptation', 1),\n",
       " ('guess', 1),\n",
       " ('there', 1),\n",
       " ('only', 1),\n",
       " ('way', 2),\n",
       " ('do', 2),\n",
       " ('may', 2),\n",
       " ('at', 1),\n",
       " (\"you're\", 1),\n",
       " ('dutch', 1),\n",
       " ('now', 2),\n",
       " ('right', 1),\n",
       " ('idea', 3),\n",
       " ('good', 1),\n",
       " ('are', 1),\n",
       " ('honking', 1),\n",
       " (\"let's\", 1),\n",
       " ('more', 1),\n",
       " ('spark', 1),\n",
       " ('a', 3),\n",
       " ('fast', 1),\n",
       " ('and', 6),\n",
       " ('general', 1),\n",
       " ('processing', 2),\n",
       " ('with', 1),\n",
       " ('data', 2),\n",
       " ('it', 5),\n",
       " ('can', 2),\n",
       " ('through', 1),\n",
       " ('or', 1),\n",
       " ('standalone', 1),\n",
       " ('hbase', 1),\n",
       " ('any', 1),\n",
       " ('inputformat', 1),\n",
       " ('to', 7),\n",
       " ('batch', 1),\n",
       " ('mapreduce', 1),\n",
       " ('workloads', 1),\n",
       " ('interactive', 1),\n",
       " ('queries', 1),\n",
       " ('beautiful', 1),\n",
       " ('better', 8),\n",
       " ('ugly', 1),\n",
       " ('explicit', 1),\n",
       " ('complex', 2),\n",
       " ('dense', 1),\n",
       " ('special', 2),\n",
       " ('enough', 1),\n",
       " ('break', 1),\n",
       " ('the', 5),\n",
       " ('practicality', 1),\n",
       " ('beats', 1),\n",
       " ('purity', 1),\n",
       " ('should', 2),\n",
       " ('silently', 1),\n",
       " ('unless', 2),\n",
       " ('face', 1),\n",
       " ('ambiguity', 1),\n",
       " ('be', 3),\n",
       " ('one', 3),\n",
       " ('preferably', 1),\n",
       " ('obvious', 2),\n",
       " ('that', 1),\n",
       " ('not', 1),\n",
       " ('first', 1),\n",
       " ('often', 1),\n",
       " ('if', 2),\n",
       " ('implementation', 2),\n",
       " ('hard', 1),\n",
       " ('explain', 2),\n",
       " (\"it's\", 1),\n",
       " ('bad', 1),\n",
       " ('easy', 1),\n",
       " ('namespaces', 1),\n",
       " ('great', 1),\n",
       " ('those', 1)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile(\"RDD_input\") \\\n",
    "    .map(lambda x: re.findall(r\"[a-z']+\", x.lower())) \\\n",
    "    .flatMap(lambda x: [(y, 1) for y in x]) \\\n",
    "    .reduceByKey(lambda x,y: x + y) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3777c8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark', 1),\n",
       " ('is', 1),\n",
       " ('a', 1),\n",
       " ('fast', 1),\n",
       " ('and', 1),\n",
       " ('general', 1),\n",
       " ('processing', 1),\n",
       " ('engine', 1),\n",
       " ('compatible', 1),\n",
       " ('with', 1),\n",
       " ('hadoop', 1),\n",
       " ('data', 1),\n",
       " ('it', 1),\n",
       " ('can', 1),\n",
       " ('run', 1),\n",
       " ('in', 1),\n",
       " ('hadoop', 1),\n",
       " ('clusters', 1),\n",
       " ('through', 1),\n",
       " ('yarn', 1),\n",
       " ('or', 1),\n",
       " (\"spark's\", 1),\n",
       " ('standalone', 1),\n",
       " ('mode', 1),\n",
       " ('and', 1),\n",
       " ('it', 1),\n",
       " ('can', 1),\n",
       " ('process', 1),\n",
       " ('data', 1),\n",
       " ('in', 1),\n",
       " ('hdfs', 1),\n",
       " ('hbase', 1),\n",
       " ('cassandra', 1),\n",
       " ('hive', 1),\n",
       " ('and', 1),\n",
       " ('any', 1),\n",
       " ('hadoop', 1),\n",
       " ('inputformat', 1),\n",
       " ('it', 1),\n",
       " ('is', 1),\n",
       " ('designed', 1),\n",
       " ('to', 1),\n",
       " ('perform', 1),\n",
       " ('both', 1),\n",
       " ('batch', 1),\n",
       " ('processing', 1),\n",
       " ('similar', 1),\n",
       " ('to', 1),\n",
       " ('mapreduce', 1),\n",
       " ('and', 1),\n",
       " ('new', 1),\n",
       " ('workloads', 1),\n",
       " ('like', 1),\n",
       " ('streaming', 1),\n",
       " ('interactive', 1),\n",
       " ('queries', 1),\n",
       " ('and', 1),\n",
       " ('machine', 1),\n",
       " ('learning', 1),\n",
       " ('beautiful', 1),\n",
       " ('is', 1),\n",
       " ('better', 1),\n",
       " ('than', 1),\n",
       " ('ugly', 1),\n",
       " ('explicit', 1),\n",
       " ('is', 1),\n",
       " ('better', 1),\n",
       " ('than', 1),\n",
       " ('implicit', 1),\n",
       " ('simple', 1),\n",
       " ('is', 1),\n",
       " ('better', 1),\n",
       " ('than', 1),\n",
       " ('complex', 1),\n",
       " ('complex', 1),\n",
       " ('is', 1),\n",
       " ('better', 1),\n",
       " ('than', 1),\n",
       " ('complicated', 1),\n",
       " ('flat', 1),\n",
       " ('is', 1),\n",
       " ('better', 1),\n",
       " ('than', 1),\n",
       " ('nested', 1),\n",
       " ('sparse', 1),\n",
       " ('is', 1),\n",
       " ('better', 1),\n",
       " ('than', 1),\n",
       " ('dense', 1),\n",
       " ('readability', 1),\n",
       " ('counts', 1),\n",
       " ('special', 1),\n",
       " ('cases', 1),\n",
       " (\"aren't\", 1),\n",
       " ('special', 1),\n",
       " ('enough', 1),\n",
       " ('to', 1),\n",
       " ('break', 1),\n",
       " ('the', 1),\n",
       " ('rules', 1),\n",
       " ('although', 1),\n",
       " ('practicality', 1),\n",
       " ('beats', 1),\n",
       " ('purity', 1),\n",
       " ('errors', 1),\n",
       " ('should', 1),\n",
       " ('never', 1),\n",
       " ('pass', 1),\n",
       " ('silently', 1),\n",
       " ('unless', 1),\n",
       " ('explicitly', 1),\n",
       " ('silenced', 1),\n",
       " ('in', 1),\n",
       " ('the', 1),\n",
       " ('face', 1),\n",
       " ('of', 1),\n",
       " ('ambiguity', 1),\n",
       " ('refuse', 1),\n",
       " ('the', 1),\n",
       " ('temptation', 1),\n",
       " ('to', 1),\n",
       " ('guess', 1),\n",
       " ('there', 1),\n",
       " ('should', 1),\n",
       " ('be', 1),\n",
       " ('one', 1),\n",
       " ('and', 1),\n",
       " ('preferably', 1),\n",
       " ('only', 1),\n",
       " ('one', 1),\n",
       " ('obvious', 1),\n",
       " ('way', 1),\n",
       " ('to', 1),\n",
       " ('do', 1),\n",
       " ('it', 1),\n",
       " ('although', 1),\n",
       " ('that', 1),\n",
       " ('way', 1),\n",
       " ('may', 1),\n",
       " ('not', 1),\n",
       " ('be', 1),\n",
       " ('obvious', 1),\n",
       " ('at', 1),\n",
       " ('first', 1),\n",
       " ('unless', 1),\n",
       " (\"you're\", 1),\n",
       " ('dutch', 1),\n",
       " ('now', 1),\n",
       " ('is', 1),\n",
       " ('better', 1),\n",
       " ('than', 1),\n",
       " ('never', 1),\n",
       " ('although', 1),\n",
       " ('never', 1),\n",
       " ('is', 1),\n",
       " ('often', 1),\n",
       " ('better', 1),\n",
       " ('than', 1),\n",
       " ('right', 1),\n",
       " ('now', 1),\n",
       " ('if', 1),\n",
       " ('the', 1),\n",
       " ('implementation', 1),\n",
       " ('is', 1),\n",
       " ('hard', 1),\n",
       " ('to', 1),\n",
       " ('explain', 1),\n",
       " (\"it's\", 1),\n",
       " ('a', 1),\n",
       " ('bad', 1),\n",
       " ('idea', 1),\n",
       " ('if', 1),\n",
       " ('the', 1),\n",
       " ('implementation', 1),\n",
       " ('is', 1),\n",
       " ('easy', 1),\n",
       " ('to', 1),\n",
       " ('explain', 1),\n",
       " ('it', 1),\n",
       " ('may', 1),\n",
       " ('be', 1),\n",
       " ('a', 1),\n",
       " ('good', 1),\n",
       " ('idea', 1),\n",
       " ('namespaces', 1),\n",
       " ('are', 1),\n",
       " ('one', 1),\n",
       " ('honking', 1),\n",
       " ('great', 1),\n",
       " ('idea', 1),\n",
       " (\"let's\", 1),\n",
       " ('do', 1),\n",
       " ('more', 1),\n",
       " ('of', 1),\n",
       " ('those', 1)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile(\"RDD_input\") \\\n",
    "    .map(lambda x: re.findall(r\"[a-z']+\", x.lower())) \\\n",
    "    .flatMap(lambda x: [(y, 1) for y in x]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "965207d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['spark',\n",
       "  'is',\n",
       "  'a',\n",
       "  'fast',\n",
       "  'and',\n",
       "  'general',\n",
       "  'processing',\n",
       "  'engine',\n",
       "  'compatible',\n",
       "  'with',\n",
       "  'hadoop',\n",
       "  'data'],\n",
       " ['it',\n",
       "  'can',\n",
       "  'run',\n",
       "  'in',\n",
       "  'hadoop',\n",
       "  'clusters',\n",
       "  'through',\n",
       "  'yarn',\n",
       "  'or',\n",
       "  \"spark's\",\n",
       "  'standalone',\n",
       "  'mode'],\n",
       " ['and',\n",
       "  'it',\n",
       "  'can',\n",
       "  'process',\n",
       "  'data',\n",
       "  'in',\n",
       "  'hdfs',\n",
       "  'hbase',\n",
       "  'cassandra',\n",
       "  'hive',\n",
       "  'and',\n",
       "  'any',\n",
       "  'hadoop',\n",
       "  'inputformat'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'designed',\n",
       "  'to',\n",
       "  'perform',\n",
       "  'both',\n",
       "  'batch',\n",
       "  'processing',\n",
       "  'similar',\n",
       "  'to',\n",
       "  'mapreduce'],\n",
       " ['and',\n",
       "  'new',\n",
       "  'workloads',\n",
       "  'like',\n",
       "  'streaming',\n",
       "  'interactive',\n",
       "  'queries',\n",
       "  'and',\n",
       "  'machine',\n",
       "  'learning'],\n",
       " [],\n",
       " [],\n",
       " ['beautiful', 'is', 'better', 'than', 'ugly'],\n",
       " ['explicit', 'is', 'better', 'than', 'implicit'],\n",
       " ['simple', 'is', 'better', 'than', 'complex'],\n",
       " ['complex', 'is', 'better', 'than', 'complicated'],\n",
       " ['flat', 'is', 'better', 'than', 'nested'],\n",
       " ['sparse', 'is', 'better', 'than', 'dense'],\n",
       " ['readability', 'counts'],\n",
       " ['special',\n",
       "  'cases',\n",
       "  \"aren't\",\n",
       "  'special',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'break',\n",
       "  'the',\n",
       "  'rules'],\n",
       " ['although', 'practicality', 'beats', 'purity'],\n",
       " ['errors', 'should', 'never', 'pass', 'silently'],\n",
       " ['unless', 'explicitly', 'silenced'],\n",
       " ['in',\n",
       "  'the',\n",
       "  'face',\n",
       "  'of',\n",
       "  'ambiguity',\n",
       "  'refuse',\n",
       "  'the',\n",
       "  'temptation',\n",
       "  'to',\n",
       "  'guess'],\n",
       " ['there',\n",
       "  'should',\n",
       "  'be',\n",
       "  'one',\n",
       "  'and',\n",
       "  'preferably',\n",
       "  'only',\n",
       "  'one',\n",
       "  'obvious',\n",
       "  'way',\n",
       "  'to',\n",
       "  'do',\n",
       "  'it'],\n",
       " ['although',\n",
       "  'that',\n",
       "  'way',\n",
       "  'may',\n",
       "  'not',\n",
       "  'be',\n",
       "  'obvious',\n",
       "  'at',\n",
       "  'first',\n",
       "  'unless',\n",
       "  \"you're\",\n",
       "  'dutch'],\n",
       " ['now', 'is', 'better', 'than', 'never'],\n",
       " ['although', 'never', 'is', 'often', 'better', 'than', 'right', 'now'],\n",
       " ['if',\n",
       "  'the',\n",
       "  'implementation',\n",
       "  'is',\n",
       "  'hard',\n",
       "  'to',\n",
       "  'explain',\n",
       "  \"it's\",\n",
       "  'a',\n",
       "  'bad',\n",
       "  'idea'],\n",
       " ['if',\n",
       "  'the',\n",
       "  'implementation',\n",
       "  'is',\n",
       "  'easy',\n",
       "  'to',\n",
       "  'explain',\n",
       "  'it',\n",
       "  'may',\n",
       "  'be',\n",
       "  'a',\n",
       "  'good',\n",
       "  'idea'],\n",
       " ['namespaces',\n",
       "  'are',\n",
       "  'one',\n",
       "  'honking',\n",
       "  'great',\n",
       "  'idea',\n",
       "  \"let's\",\n",
       "  'do',\n",
       "  'more',\n",
       "  'of',\n",
       "  'those']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile(\"RDD_input\") \\\n",
    "    .map(lambda x: re.findall(r\"[a-z']+\", x.lower())).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f90191",
   "metadata": {},
   "source": [
    "> ZADANIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ef05b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MOBY DICK;',\n",
       " '',\n",
       " '',\n",
       " 'or, THE WHALE.',\n",
       " '',\n",
       " '',\n",
       " 'CHAPTER 1. Loomings.',\n",
       " '',\n",
       " 'Call me Ishmael. Some years ago—never mind how long precisely—having',\n",
       " 'little or no money in my purse, and nothing particular to interest me on']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawMD = sc.textFile(\"MobyDick.txt\")\n",
    "rawMD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0482a4f0",
   "metadata": {},
   "source": [
    "### SQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d559ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adultDF = spark.read.csv(\"adult.data\", inferSchema=True, ignoreLeadingWhiteSpace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47ade9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0=39, _c1='State-gov', _c2=77516, _c3='Bachelors', _c4=13, _c5='Never-married', _c6='Adm-clerical', _c7='Not-in-family', _c8='White', _c9='Male', _c10=2174, _c11=0, _c12=40, _c13='United-States', _c14='<=50K')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultDF.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4350553",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\"marital-status\", \"occupation\", \n",
    "             \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \n",
    "             \"native-country\", \"earnings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "979a8efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "adultDF = adultDF.toDF(*col_names).drop(\"fnlwgt\").dropna(\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0016f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------\n",
      " age            | 39                 \n",
      " workclass      | State-gov          \n",
      " education      | Bachelors          \n",
      " education-num  | 13                 \n",
      " marital-status | Never-married      \n",
      " occupation     | Adm-clerical       \n",
      " relationship   | Not-in-family      \n",
      " race           | White              \n",
      " sex            | Male               \n",
      " capital-gain   | 2174               \n",
      " capital-loss   | 0                  \n",
      " hours-per-week | 40                 \n",
      " native-country | United-States      \n",
      " earnings       | <=50K              \n",
      "-RECORD 1----------------------------\n",
      " age            | 50                 \n",
      " workclass      | Self-emp-not-inc   \n",
      " education      | Bachelors          \n",
      " education-num  | 13                 \n",
      " marital-status | Married-civ-spouse \n",
      " occupation     | Exec-managerial    \n",
      " relationship   | Husband            \n",
      " race           | White              \n",
      " sex            | Male               \n",
      " capital-gain   | 0                  \n",
      " capital-loss   | 0                  \n",
      " hours-per-week | 13                 \n",
      " native-country | United-States      \n",
      " earnings       | <=50K              \n",
      "-RECORD 2----------------------------\n",
      " age            | 38                 \n",
      " workclass      | Private            \n",
      " education      | HS-grad            \n",
      " education-num  | 9                  \n",
      " marital-status | Divorced           \n",
      " occupation     | Handlers-cleaners  \n",
      " relationship   | Not-in-family      \n",
      " race           | White              \n",
      " sex            | Male               \n",
      " capital-gain   | 0                  \n",
      " capital-loss   | 0                  \n",
      " hours-per-week | 40                 \n",
      " native-country | United-States      \n",
      " earnings       | <=50K              \n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adultDF.show(3, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf44800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- education-num: integer (nullable = true)\n",
      " |-- marital-status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- capital-gain: integer (nullable = true)\n",
      " |-- capital-loss: integer (nullable = true)\n",
      " |-- hours-per-week: integer (nullable = true)\n",
      " |-- native-country: string (nullable = true)\n",
      " |-- earnings: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adultDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8af946f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+---------+-------------+------------------+-----------------+-------------+-----+----+------------+------------+--------------+--------------+--------+\n",
      "|age|       workclass|education|education-num|    marital-status|       occupation| relationship| race| sex|capital-gain|capital-loss|hours-per-week|native-country|earnings|\n",
      "+---+----------------+---------+-------------+------------------+-----------------+-------------+-----+----+------------+------------+--------------+--------------+--------+\n",
      "| 39|       State-gov|Bachelors|           13|     Never-married|     Adm-clerical|Not-in-family|White|Male|        2174|           0|            40| United-States|   <=50K|\n",
      "| 50|Self-emp-not-inc|Bachelors|           13|Married-civ-spouse|  Exec-managerial|      Husband|White|Male|           0|           0|            13| United-States|   <=50K|\n",
      "| 38|         Private|  HS-grad|            9|          Divorced|Handlers-cleaners|Not-in-family|White|Male|           0|           0|            40| United-States|   <=50K|\n",
      "+---+----------------+---------+-------------+------------------+-----------------+-------------+-----+----+------------+------------+--------------+--------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adultDF.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "586f7da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|   education|          avg(age)|avg(education-num)| avg(capital-gain)| avg(capital-loss)|avg(hours-per-week)|\n",
      "+------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|     Masters| 44.04991294254208|              14.0| 2562.563551944283|166.71967498549043|  43.83633197910621|\n",
      "|        10th| 37.42979635584137|               6.0|404.57449088960345|56.845659163987136| 37.052518756698824|\n",
      "|     5th-6th|42.885885885885884|               3.0|176.02102102102103| 68.25225225225225|   38.8978978978979|\n",
      "|  Assoc-acdm|37.381443298969074|              12.0| 640.3992502343018| 93.41893158388004| 40.504217432052485|\n",
      "|   Assoc-voc| 38.55354558610709|              11.0| 715.0513748191028| 72.75470332850941|  41.61070911722142|\n",
      "|     7th-8th| 48.44582043343653|               4.0|233.93962848297213|  65.6687306501548|  39.36687306501548|\n",
      "|         9th| 41.06031128404669|               5.0|342.08949416342415| 28.99805447470817|  38.04474708171206|\n",
      "|     HS-grad|38.974478621083705|               9.0|  576.800114274831| 70.46662222645462| 40.575373773926295|\n",
      "|   Bachelors| 38.90494864612511|              13.0| 1756.299533146592|118.35032679738562| 42.614005602240894|\n",
      "|        11th| 32.35574468085106|               7.0|215.09787234042554| 50.07914893617021|  33.92595744680851|\n",
      "|     1st-4th|46.142857142857146|               2.0|           125.875| 48.32738095238095|  38.25595238095238|\n",
      "|   Preschool| 42.76470588235294|               1.0| 898.3921568627451| 66.49019607843137|  36.64705882352941|\n",
      "|        12th|              32.0|               8.0| 284.0877598152425| 32.33718244803695|  35.78060046189376|\n",
      "|   Doctorate| 47.70217917675545|              16.0| 4770.145278450364| 262.8450363196126| 46.973365617433416|\n",
      "|Some-college| 35.75627485941572|              10.0| 598.8241667809629| 71.63708681936635|  38.85228363736113|\n",
      "| Prof-school| 44.74652777777778|              15.0|10414.416666666666|        231.203125|  47.42534722222222|\n",
      "+------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adultDF.groupBy('education').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2795adb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "adultDF.write.saveAsTable(\"adult_bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "70d66dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "newAdult = spark.sql(\"select age, education, sex from adult_bucket where age > 50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3012dcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+\n",
      "|age|education|   sex|\n",
      "+---+---------+------+\n",
      "| 53|     11th|  Male|\n",
      "| 52|  HS-grad|  Male|\n",
      "| 54|  HS-grad|Female|\n",
      "+---+---------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newAdult.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02160d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
